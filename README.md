# CVxVacancyMatcher
The text-based service for the matching of job descriptions and CVs for enhanced recruitment precision [NLP course study project]

## Работа с данными, EDA

Создан датасет с текстами вакансий и резюме на основе данных hh.ru

- [Оригинальный датасет](https://drive.google.com/file/d/1rmkQVvLH9A5428o6ReziCTGGnlRrAnys/view?usp=sharing)

- [Итоговый датасет](https://drive.google.com/file/d/1usnDtA6_xeCDUmk3EuwffC5dcp28b6Iq/view?usp=sharing)

По результатам анализа данных пришли к выводу о том, что информации мало (нет данных об опыте в случае резюме, нет описания в случае вакансии), поэтому приняли решение перейти к другому датасету


- [Вакансии](https://www.kaggle.com/datasets/ivangurin/vacancyhh)

- [Резюме](https://drive.google.com/file/d/1ikA_Ht45fXD2w5dWZ9sGTSRl-UNeCVub/view?usp=share_link)

По результатам анализа данных приняли решение не удалять пропуски, т. к. вакансии и резюме не всегда заполняются полностью и удалять такие данные было бы ошибочно.
Также было замечено, что датасет с резюме содержит ошибки (иногда в поле "Опыт работы" дублируются данные из дургих полей), вычистить с помощью redex не удалось. 

## Эксперименты

### Энкодеры

[Ноутбук](./experiments/embeddings.ipynb)

Были протестированы модели:
- rubert-tiny2
- paraphrase-multilingual-mpnet-base-v2

На основе табличных данных по шаблону было составлено поле с текстами вакансий/резюме. Для каждого текста были посчитаны эмбеддинги с помощью двух моделей, после чего выдавались рекомендации на основе косинусного сходства.

Модель **paraphrase-multilingual-mpnet-base-v2** показала себя немного лучше в случае поиска резюме по вакансии, в ином случае модель **rubert-tiny2** оказалась куда более точной.

### NER

[Ноутбук](./experiments/NER.ipynb)

Протестировали пакет [natasha](https://natasha.github.io/?ysclid=lqd17btfjp94158319) с целью выделения данных о локации из вакансий/резюме. Проблема в том, что зачастую захватываются лишние слова либо локации, которые связаны с предыдущим местом работы/местом учебы и т. д., которые будут только запутывать нас при подборе резюме/вакансии. Поэтому решили попробовать qusteion-answering модели, чтобы доставать данные о локациях из текста.

### QA модели

[Ноутбук](./experiments/QAmodels.ipynb)

Протестированы следующие предобученные модели:
- Den4ikAI/rubert-large-squad (среднее время инференса - 0.7 с)
- AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru (среднее время инференса - 2.2 с)
- timpal0l/mdeberta-v3-base-squad2 (среднее время инференса - 2.3 с)

QA модели работают не стабильно (иногда при вопросе о месте жительства соискателя могут достать например город из опыта работы) и зависят от запроса.
Учитывая, что требуется задать 5 вопросов (должность, место, навыки, зарплата, график), только чтобы достать фичи из текста потребуется в лучшем случае около 3.5 секунд.

### keyBERT

[Ноутбук](./experiments/keywords.ipynb)

Не удалось подобрать параметры и модель для векторизации русскоязычного текста, которые позволили бы стабильно доставать из текста резюме/вакансии полезные данные. 

### BERTopic

[Ноутбук](./experiments/berttopic.ipynb)

На данный момент многие вакансии/резюме помечаются как шум.
Метод кажется перспективным, нужно продолжать подбор гибперпараметров.
Нужно обратить внимание на метрики расстояния для векторов высокой размерности. В данной имплементации метрика косинусного сходства недоступна, возможно проблема в этом.

## Сервис

Для сервиса используется Fastapi и Streamlit

Пользователю предлагается выбрать, что он ищет: вакансию или резюме, ввести свои соответствующие данные (резюме или вакансия соответственно) и получить результат в виде 5 наиболее подходящих вакансий/резюме.

На данный момент сервис работает на косинусном сходстве, планируется добавить обученную модель BERTopic

### Принцип работы

Данные с текстами вакансий/резюме и их эмбеддингами хранятся локально (на стороне сервера) в виде pandas dataframe

1. Пользователеь отправляет текст резюме/вакансии
2. Полученный текст кодируется в вектор с помощью модели `cointegrated/rubert-tiny2` если это резюме, если же введен текст вакансии, то используем `paraphrase-multilingual-mpnet-base-v2`
3. Для полученного вектора считается косинусное сходство для всех имеющихся вакансий или резюме соответственно
4. Выбираются топ 5 текстов с наибольши значением косинусного сходства и отправлются пользователю

### [Демо](https://drive.google.com/file/d/1NLSMu2JNsXOeqM0IwbOsg9jB4qqOrOmf/view?usp=sharing)

### Скорость

Скорость разная для поиска вакансий и резюме, т. к. используем разные модели

- Для поиска резюме скорость от 19 до 21 секунды
- Для поиска вакансии скорость от 9 до 11 секунд