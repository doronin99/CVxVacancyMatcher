# CVxVacancyMatcher
The text-based service for the matching of job descriptions and CVs for enhanced recruitment precision [NLP course study project]

## Работа с данными, EDA

Создан датасет с текстами вакансий и резюме на основе данных hh.ru

- [Оригинальный датасет](https://drive.google.com/file/d/1rmkQVvLH9A5428o6ReziCTGGnlRrAnys/view?usp=sharing)

- [Итоговый датасет](https://drive.google.com/file/d/1usnDtA6_xeCDUmk3EuwffC5dcp28b6Iq/view?usp=sharing)

По результатам анализа данных пришли к выводу о том, что информации мало (нет данных об опыте в случае резюме, нет описания в случае вакансии), поэтому приняли решение перейти к другому датасету

- [Вакансии](https://www.kaggle.com/datasets/ivangurin/vacancyhh)

- [Резюме](https://drive.google.com/file/d/1ikA_Ht45fXD2w5dWZ9sGTSRl-UNeCVub/view?usp=share_link)

По результатам анализа данных приняли решение не удалять пропуски, т. к. вакансии и резюме не всегда заполняются полностью и удалять такие данные было бы ошибочно.
Также было замечено, что датасет с резюме содержит ошибки (иногда в поле "Опыт работы" дублируются данные из дургих полей), вычистить с помощью redex не удалось. 

## Эксперименты

### Энкодеры

[Ноутбук](./experiments/embeddings.ipynb)

Были протестированы модели:
- rubert-tiny2
- paraphrase-multilingual-mpnet-base-v2

На основе табличных данных по шаблону было составлено поле с текстами вакансий/резюме. Для каждого текста были посчитаны эмбеддинги с помощью двух моделей, после чего выдавались рекомендации на основе косинусного сходства.

Так как используемые данные не размечены, то оценивать качество эмбеддингов было решено основываясь на оценках участников команды проекта. Для каждого участника команды выбиралось случайные резюме и вакансия, для которых подбирали 5 наиболее подходящих по косинусному сходству вакансий или резюме соответственно для каждого из тестируемых энкодеров.

- Модель **paraphrase-multilingual-mpnet-base-v2** показала себя немного лучше в случае поиска резюме по вакансии, в ином случае модель **rubert-tiny2** оказалась куда более точной. 
- используя эмбеддинги **paraphrase-multilingual-mpnet-base-v2** на любое резюме подбирались вакансии связанные с оператором станков ЧПУ, поэтому для поиска вакансии по резюме решено было использовать **rubert-tiny2**, рекомендации вакансий, сделанные на основе эмбеддингов, полученных при помощи **rubert-tiny2**, оказались более релевантными по нашему мнению
- в случае поиска резюме по вакансии эмбеддинги **rubert-tiny2** позволили находить резюме спецималистов в смежных сферах деятельности, в то время как используя эмбеддинги **paraphrase-multilingual-mpnet-base-v2** получилось находить резюме с такой же должностью и иногда с требуемым в вакансии технологическим стеком

### NER

[Ноутбук](./experiments/NER.ipynb)

Протестировали пакет [natasha](https://natasha.github.io/?ysclid=lqd17btfjp94158319) с целью выделения данных о локации из вакансий/резюме. Проблема в том, что зачастую захватываются лишние слова либо локации, которые связаны с предыдущим местом работы/местом учебы и т. д., которые будут только запутывать нас при подборе резюме/вакансии. Поэтому решили попробовать qusteion-answering модели, чтобы доставать данные о локациях из текста.

### QA модели

[Ноутбук](./experiments/QAmodels.ipynb)

Протестированы следующие предобученные модели:
- Den4ikAI/rubert-large-squad (среднее время инференса - 0.7 с)
- AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru (среднее время инференса - 2.2 с)
- timpal0l/mdeberta-v3-base-squad2 (среднее время инференса - 2.3 с)

QA модели работают не стабильно (иногда при вопросе о месте жительства соискателя могут достать например город из опыта работы) и зависят от запроса.
Учитывая, что требуется задать 5 вопросов (должность, место, навыки, зарплата, график), только чтобы достать фичи из текста потребуется в лучшем случае около 3.5 секунд.

### keyBERT

[Ноутбук](./experiments/keywords.ipynb)

Не удалось подобрать параметры и модель для векторизации русскоязычного текста, которые позволили бы стабильно доставать из текста резюме/вакансии полезные данные. 

### BERTopic

[Ноутбук](./experiments/berttopic.ipynb)

На данный момент многие вакансии/резюме помечаются как шум.
Метод кажется перспективным, нужно продолжать подбор гибперпараметров.
Нужно обратить внимание на метрики расстояния для векторов высокой размерности. В данной имплементации метрика косинусного сходства недоступна, возможно проблема в этом.

## Сервис

Для сервиса используется Fastapi и Streamlit

Пользователю предлагается выбрать, что он ищет: вакансию или резюме, ввести свои соответствующие данные (резюме или вакансия соответственно) и получить результат в виде 5 наиболее подходящих вакансий/резюме.

На данный момент сервис работает на косинусном сходстве, планируется добавить обученную модель BERTopic

### Принцип работы

Данные с текстами вакансий/резюме и их эмбеддингами хранятся локально (на стороне сервера) в виде pandas dataframe

1. Пользователеь отправляет текст резюме/вакансии
2. Полученный текст кодируется в вектор с помощью модели `cointegrated/rubert-tiny2` если это резюме, если же введен текст вакансии, то используем `paraphrase-multilingual-mpnet-base-v2`
3. Для полученного вектора считается косинусное сходство для всех имеющихся вакансий или резюме соответственно
4. Выбираются топ 5 текстов с наибольши значением косинусного сходства и отправлются пользователю

### [Демо](https://drive.google.com/file/d/1NLSMu2JNsXOeqM0IwbOsg9jB4qqOrOmf/view?usp=sharing)

### Скорость

Замерялось время, которое требовалось на вычисление эмбеддинга входного текста, вычисление значения косинусного сходства между эмбеддингом входного текста и эмбеддингами сохраненных текстов, сортировка массива полученных значений косинусного сходства и выбор

Для замера скорости были выбраны случайные 10 текстов резюме и 10 текстов вакансий, для каждого из которых был выполнен рассчет скорости обработки описанным выше способом

Используемые данные:

- [корпус текстов резюме c эмбеддингами](https://drive.google.com/file/d/1jWcNE9gj3bktM_CO28wwnErOTNPvWcVX/view?usp=sharing)
- [корпус текстов вакансий с эмбеддингами](https://drive.google.com/file/d/1q9uY2jFTXnKQCgxxl5URsKNIbB4NdFDH/view?usp=sharing)

Время инференса замерялось на RTX 4070TI

Скорость разная для поиска вакансий и резюме, т. к. используем разные модели

- Для поиска резюме скорость от 19 до 21 секунды
- Для поиска вакансии скорость от 9 до 11 секунд